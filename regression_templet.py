# -*- coding: utf-8 -*-
"""Regression templet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11jydjUZMzDL0_ILq3-2AVrEJI-Lakt9r

# Importing the libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# Loading dataset and performing some basic preprocessing"""

data = pd.read_csv("upload the dataset here")
data.head()

data.isnull().sum()

data.info()

data.describe()

X = data.iloc[:,:-1].values
y = data.iloc[:,-1:].values

"""# Spliting the dataset for training and testing"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)

"""# Performing feature scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

sc_y = StandardScaler()
y_train = sc_y.fit_transform(y_train)
y_test = sc_y.transform(y_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
model = []
mse = []
mae = []
rmse = []
r2 = []

"""# mutiple linear regression model"""

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train, y_train)

liner_y_p = regressor.predict(X_test)
model.append("Multi-linear Rewgression")
mae.append(mean_absolute_error(y_test, liner_y_p))
mse.append(mean_squared_error(y_test, liner_y_p))
rmse.append(np.sqrt(mse[0]))
r2.append(r2_score(y_test, liner_y_p))

"""# polynomial regression"""

from sklearn.preprocessing import PolynomialFeatures
poly_reg = PolynomialFeatures(degree = 4)
X_poly = poly_reg.fit_transform(X_train)
lin_reg_2 = LinearRegression()
lin_reg_2.fit(X_poly, y_train)

poly_y_p = lin_reg_2.predict(poly_reg.fit_transform(X_test))
model.append("Polynomial Rewgression")
mae.append(mean_absolute_error(y_test, poly_y_p))
mse.append(mean_squared_error(y_test, poly_y_p))
rmse.append(np.sqrt(mse[1]))
r2.append(r2_score(y_test, poly_y_p))

"""# support vector regression"""

from sklearn.svm import SVR
svr = SVR(kernel = 'rbf')
svr.fit(X_train, y_train)

svr_y_p = svr.predict(X_test)
model.append("Support vector Regression")
mae.append(mean_absolute_error(y_test, svr_y_p))
mse.append(mean_squared_error(y_test, svr_y_p))
rmse.append(np.sqrt(mse[2]))
r2.append(r2_score(y_test, svr_y_p))

"""# decision tree regression"""

from sklearn.tree import DecisionTreeRegressor
dt = DecisionTreeRegressor(random_state = 42)
dt.fit(X_train, y_train)

dt_y_p = dt.predict(X_test)
model.append("Decision tree Regression")
mae.append(mean_absolute_error(y_test, dt_y_p))
mse.append(mean_squared_error(y_test, dt_y_p))
rmse.append(np.sqrt(mse[0]))
r2.append(r2_score(y_test, dt_y_p))

"""# random forest regression"""

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(n_estimators = 50, random_state = 42)
rf.fit(X_train, y_train)

rf_y_p = rf.predict(X_test)
model.append("Random forest Regression")
mae.append(mean_absolute_error(y_test, rf_y_p))
mse.append(mean_squared_error(y_test, rf_y_p))
rmse.append(np.sqrt(mse[0]))
r2.append(r2_score(y_test, rf_y_p))

"""# XGboost"""

import xgboost
xg = xgboost.XGBRegressor()
xg.fit(X_train, y_train)

xg_y_p = xg.predict(X_test)
model.append("XGBoost Regression")
mae.append(mean_absolute_error(y_test, xg_y_p))
mse.append(mean_squared_error(y_test, xg_y_p))
rmse.append(np.sqrt(mse[0]))
r2.append(r2_score(y_test, rf_y_p))

"""# Performance Results"""

performance = pd.DataFrame({"Regression Models":model, "Mean_Absolute_Error":mae, "Mean_Squared_Error":mse, "Root_Mean_Squared_Error":rmse, "R2_Score":r2})
pd.options.display.float_format = "{:.5f}".format
performance